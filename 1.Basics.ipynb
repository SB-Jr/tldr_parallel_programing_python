{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No of Cores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The no of cores dictate the no of parallel processess we can run. To get the no of cores we will use the `multiprocessing` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-07T12:21:46.796505Z",
     "iopub.status.busy": "2020-06-07T12:21:46.796158Z",
     "iopub.status.idle": "2020-06-07T12:21:46.803440Z",
     "shell.execute_reply": "2020-06-07T12:21:46.802641Z",
     "shell.execute_reply.started": "2020-06-07T12:21:46.796474Z"
    }
   },
   "outputs": [],
   "source": [
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-07T12:22:02.251523Z",
     "iopub.status.busy": "2020-06-07T12:22:02.251299Z",
     "iopub.status.idle": "2020-06-07T12:22:02.255857Z",
     "shell.execute_reply": "2020-06-07T12:22:02.255029Z",
     "shell.execute_reply.started": "2020-06-07T12:22:02.251497Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(mp.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synchronous vs Asynchronous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In parallel processing, there are two types of execution: Synchronous and Asynchronous.\n",
    "\n",
    "A synchronous execution is one the processes are completed in the same order in which it was started. This is achieved by locking the main program until the respective processes are finished.\n",
    "\n",
    "Asynchronous, on the other hand, doesnâ€™t involve locking. As a result, the order of results can get mixed up but usually gets done quicker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes to implement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 main objects in multiprocessing to implement parallel execution of a function: The Pool Class and the Process Class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 main objects in multiprocessing to implement parallel execution of a function: The `Pool` Class and the `Process` Class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Synchronous execution:\n",
    "- Pool.map()\n",
    "- Pool.starmap()\n",
    "- Pool.apply()\n",
    "\n",
    "For Asynchronous execution:\n",
    "- Pool.map_async()\n",
    "- Pool.starmap_async()\n",
    "- Pool.apply_async()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply vs Map vs StarMap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the arguments passed in `args` parameter is passed to the apply function as it is.\n",
    "But for map and starmap, the arguments that can be passed is only 1 itterable object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For map and starmap the difference lies in the itterable object. The itterable object can comprise of further itterable objects in case of starmap whereas in case of map it has to comprise of normal items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordinary vs Asycn functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case of ordinary apply, map and starmap functions the `args` is the only argument we need to pass. In this scenario, the processes are finshed in the same order it has been started.\n",
    "\n",
    "Whereas in case of Async functions, another function called as the `callback` function has to be passed. This function is called after each process is done executing its job and this the place where we handle the collection of results. If we dont pass this function then the pool will return a collection of `pool.ApplyResult` objects which contain the computed values from each process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other major difference between imap/imap_unordered and map/map_async, is that <b>with imap/imap_unordered, you can start receiving results from workers as soon as they're ready</b>, rather than having to wait for all of them to be finished. With <b>map_async, an AsyncResult is returned right away, but you can't actually retrieve results from that object until all of them have been processed</b>, at which points it returns the same list that map does (map is actually implemented internally as map_async(...).get()). There's no way to get partial results; you either have the entire result, or nothing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working of map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`map` consumes your iterable by converting the iterable to a list (assuming it isn't a list already), breaking it into chunks, and sending those chunks to the worker processes in the Pool. Breaking the iterable into chunks performs better than passing each item in the iterable between processes one item at a time - particularly if the iterable is large. However, turning the iterable into a list in order to chunk it can have a very high memory cost, since the entire list will need to be kept in memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`imap` doesn't turn the iterable you give it into a list, nor does break it into chunks (by default). It will iterate over the iterable one element at a time, and send them each to a worker process. This means you don't take the memory hit of converting the whole iterable to a list, but it also means the performance is slower for large iterables, because of the lack of chunking. This can be mitigated by passing a chunksize argument larger than default of 1, however."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-gpu] *",
   "language": "python",
   "name": "conda-env-tf-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
